{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0dbd495",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier as RFR\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42c72042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291 thi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001 ( see at...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat ho ho ho , we ' re aroun...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs this deal is to b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                               text  \\\n",
       "0         605   ham  Subject: enron methanol ; meter # : 988291 thi...   \n",
       "1        2349   ham  Subject: hpl nom for january 9 , 2001 ( see at...   \n",
       "2        3624   ham  Subject: neon retreat ho ho ho , we ' re aroun...   \n",
       "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4        2030   ham  Subject: re : indian springs this deal is to b...   \n",
       "\n",
       "   label_num  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"spam_ham_dataset.csv\")\n",
    "df.replace({r'\\r\\n':' '}, regex=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "624e1af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "label         0\n",
       "text          0\n",
       "label_num     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9f3ea72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5171, 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "091dd090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "3474    False\n",
       "3452    False\n",
       "3451    False\n",
       "3450    False\n",
       "        ...  \n",
       "1722    False\n",
       "1721    False\n",
       "1720    False\n",
       "1719    False\n",
       "5170    False\n",
       "Length: 5171, dtype: bool"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ff7a32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "\n",
    "all_stop_words = set(stopwords.words('english'))\n",
    "all_stop_words.remove('not')\n",
    "\n",
    "for i in range (len(df)):\n",
    "    text = df['text'][i].lower().translate(str.maketrans('','', string.punctuation)).split()\n",
    "    text = [ps.stem(word) for word in text if word not in all_stop_words]\n",
    "    text = ' '.join(text)\n",
    "    corpus.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89e4a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostCommon = Counter(corpus).most_common(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6546591b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features= 42500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = df['label_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f75a0bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "70c279bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_score(y_true,y_pred):\n",
    "    acc_scor = accuracy_score(y_true, y_pred)\n",
    "    prec_scor = precision_score(y_true, y_pred)\n",
    "    recall_scor = recall_score(y_true, y_pred)\n",
    "    f1_scor = f1_score(y_true, y_pred)\n",
    "    overall_avg_score = (acc_scor + prec_scor + recall_scor + f1_scor) / 4\n",
    "\n",
    "    print(f'Model accuracy score: {acc_scor}')\n",
    "    print(f'Model precision score: {prec_scor}')\n",
    "    print(f'Model recall score: {recall_scor}')\n",
    "    print(f'Model f1 score: {f1_scor}')\n",
    "    print(f'Average overall score performance: {overall_avg_score}')\n",
    "\n",
    "    print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e751210",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_rf = RFR(n_estimators=100, random_state=42)\n",
    "cl_rf.fit(X_train, y_train)\n",
    "y_pred = cl_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b033eee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.column_stack((y_test[:15], y_pred[:15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9895f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score: 0.9719806763285024\n",
      "Model precision score: 0.9506578947368421\n",
      "Model recall score: 0.9537953795379538\n",
      "Model f1 score: 0.9522240527182867\n",
      "Average overall score performance: 0.9571645008303963\n",
      "[[717  15]\n",
      " [ 14 289]]\n"
     ]
    }
   ],
   "source": [
    "model_score(y_test,y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
